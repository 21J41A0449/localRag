# ğŸ§  DocuMind AI - Agentic RAG

A production-ready **offline RAG (Retrieval-Augmented Generation)** application with intelligent agentic reasoning, hybrid search, and advanced PDF parsing.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-purple.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¤– **Agentic RAG** | Query decomposition, multi-step retrieval, self-verification |
| ğŸ” **Hybrid Search** | Combines FAISS semantic + BM25 keyword search with RRF |
| ğŸ“„ **Advanced PDF Parsing** | Tables, images, flowcharts via Unstructured |
| ğŸ”’ **100% Offline** | Works without internet using Ollama |
| ğŸ“ **Source Citations** | Every answer includes page references |
| ğŸ¨ **Modern UI** | Premium dark theme with glassmorphism |

## ğŸ“¸ Screenshot

![DocuMind AI Interface](https://via.placeholder.com/800x450?text=DocuMind+AI+Interface)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Query                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ§  Agentic Pipeline                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Analyze  â”‚â†’ â”‚Decompose â”‚â†’ â”‚ Retrieve â”‚â†’ â”‚ Verify   â”‚    â”‚
â”‚  â”‚Complexityâ”‚  â”‚ Query    â”‚  â”‚ (Hybrid) â”‚  â”‚ Context  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ” Hybrid Retrieval                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  FAISS Semantic â”‚ â”€â”€â–º â”‚  Reciprocal     â”‚                â”‚
â”‚  â”‚     Search      â”‚     â”‚  Rank Fusion    â”‚ â”€â”€â–º Results    â”‚
â”‚  â”‚  BM25 Keyword   â”‚ â”€â”€â–º â”‚                 â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- [Ollama](https://ollama.ai) installed

### 1. Install Ollama Models

```bash
ollama pull qwen2.5:3b
ollama pull nomic-embed-text
```

### 2. Clone & Install

```bash
git clone https://github.com/21J41A0449/localRag.git
cd localRag

# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 3. Run

```bash
python run.py
```

Open http://localhost:8000 in your browser.

## ğŸ“ Project Structure

```
localRag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agent.py              # Agentic RAG pipeline
â”‚   â”œâ”€â”€ hybrid_retrieval.py   # BM25 + FAISS hybrid search
â”‚   â”œâ”€â”€ advanced_ingestion.py # Unstructured PDF parsing
â”‚   â”œâ”€â”€ embeddings.py         # FAISS vector store
â”‚   â”œâ”€â”€ retrieval.py          # Semantic search
â”‚   â”œâ”€â”€ rag_chain.py          # Basic RAG chain
â”‚   â”œâ”€â”€ llm.py                # Ollama integration
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â””â”€â”€ main.py               # FastAPI backend
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html            # Web interface
â”‚   â”œâ”€â”€ styles.css            # Premium styling
â”‚   â””â”€â”€ app.js                # Frontend logic
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                 # Uploaded documents
â”‚   â””â”€â”€ vectorstore/          # FAISS index
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.py                    # Entry point
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `app/config.py` or use environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `RAG_LLM_MODEL` | `qwen2.5:3b` | Ollama LLM model |
| `RAG_EMBEDDING_MODEL` | `nomic-embed-text` | Embedding model |
| `RAG_CHUNK_SIZE` | `800` | Text chunk size |
| `RAG_TOP_K` | `4` | Retrieved chunks |
| `RAG_TEMPERATURE` | `0` | LLM temperature |

### Switch Models

```bash
# Use smaller model for low RAM
ollama pull phi3:mini
# Then update RAG_LLM_MODEL=phi3:mini
```

## ğŸ› ï¸ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/upload` | POST | Upload PDFs |
| `/query` | POST | Ask question |
| `/documents` | GET | List documents |
| `/documents/{name}` | DELETE | Delete document |
| `/health` | GET | Health check |
| `/metadata` | GET | Document metadata |

## ğŸ’¡ How It Works

### Agentic Pipeline

1. **Query Analysis** - Detects complexity (simple/moderate/complex)
2. **Decomposition** - Breaks complex questions into sub-queries
3. **Hybrid Retrieval** - Searches using both semantic and keyword methods
4. **Verification** - Checks if context answers the question
5. **Synthesis** - Generates grounded answer with citations

### Hybrid Search

Combines two retrieval methods using Reciprocal Rank Fusion:
- **FAISS** (Semantic) - Finds conceptually similar content
- **BM25** (Keyword) - Finds exact term matches

## ğŸ¤ Contributing

Pull requests welcome! Please read contributing guidelines first.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

---

Built with â¤ï¸ using LangChain, Ollama, and FastAPI
